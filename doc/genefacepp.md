[ğŸ“˜ä½¿ç”¨æ–‡æ¡£]() |
[ğŸ› å®‰è£…æ•™ç¨‹]() |
[ğŸ‘€æ¨¡å‹åº“]() |
[ğŸ†•æ›´æ–°æ—¥å¿—]() |
[ğŸš€è¿›è¡Œä¸­çš„é¡¹ç›®]() |
[ğŸ¤”æŠ¥å‘Šé—®é¢˜]()


**æ•°æ®å¤„ç†**

```
# ä»è§†é¢‘ä¸­æŠ½å‡ºä¸€å¸§
ffmpeg -i input.mp4 -vf "fps=1/60" output_%03d.png

# è§†é¢‘ä¸­å°†äººè„¸åŒºåŸŸè£å‰ªå‡ºæ¥
ffmpeg -i sn_test.mp4 -filter:v "crop=453:388:315:11" sn_test_face.mp4

# æ­¥éª¤0. å°†è§†é¢‘Cropåˆ°512x512åˆ†è¾¨ç‡ï¼Œ25FPSï¼Œç¡®ä¿æ¯ä¸€å¸§éƒ½æœ‰ç›®æ ‡äººè„¸
export PYTHONPATH=./
export VIDEO_ID=sn429_face
ffmpeg -i data/raw/videos/${VIDEO_ID}.mp4 -vf fps=25,scale=w=512:h=512 -qmin 1 -q:v 1 data/raw/videos/${VIDEO_ID}_512.mp4
mv data/raw/videos/${VIDEO_ID}.mp4 data/raw/videos/${VIDEO_ID}_to_rm.mp4
mv data/raw/videos/${VIDEO_ID}_512.mp4 data/raw/videos/${VIDEO_ID}.mp4

# æ­¥éª¤1: æå–éŸ³é¢‘ç‰¹å¾, å¦‚mel, f0, hubuert
mkdir -p data/processed/videos/${VIDEO_ID}
ffmpeg -i data/raw/videos/${VIDEO_ID}.mp4 -f wav -ar 16000 data/processed/videos/${VIDEO_ID}/aud.wav 
python data_gen/utils/process_audio/extract_hubert.py --video_id=${VIDEO_ID}
python data_gen/utils/process_audio/extract_mel_f0.py --video_id=${VIDEO_ID

# æ­¥éª¤2. æå–å›¾ç‰‡
mkdir -p data/processed/videos/${VIDEO_ID}/gt_imgs
ffmpeg -i data/raw/videos/${VIDEO_ID}.mp4 -vf fps=25,scale=w=512:h=512 -qmin 1 -q:v 1 -start_number 0 data/processed/videos/${VIDEO_ID}/gt_imgs/%08d.jpg
python data_gen/utils/process_video/extract_segment_imgs.py --ds_name=nerf --vid_dir=data/raw/videos/${VIDEO_ID}.mp4 # extract image, segmap, and background

æ­¥éª¤3. æå–lm2d_mediapipe
æå–2D landmarkç”¨äºä¹‹åFit 3DMM
num_workersæ˜¯æœ¬æœºä¸Šçš„CPU workeræ•°é‡ï¼›total_processæ˜¯ä½¿ç”¨çš„æœºå™¨æ•°ï¼›process_idæ˜¯æœ¬æœºçš„ç¼–å·
python data_gen/utils/process_video/extract_lm2d.py --ds_name=nerf --vid_dir=data/raw/videos/${VIDEO_ID}.mp4

æ­¥éª¤3. Fit 3DMM
python data_gen/utils/process_video/fit_3dmm_landmark.py --ds_name=nerf --vid_dir=data/raw/videos/${VIDEO_ID}.mp4 --reset  --debug --id_mode=global

æ­¥éª¤4. Binarizeï¼ˆå°†æ•°æ®æ‰“åŒ…ï¼‰
python data_gen/runs/binarizer_nerf.py --video_id=${VIDEO_ID}
```

**è®­ç»ƒ**

```
# è®­ç»ƒ Head NeRF æ¨¡å‹
# æ¨¡å‹ä¸tensorboardä¼šè¢«ä¿å­˜åœ¨ `checkpoints/<exp_name>`
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config=egs/datasets/May/lm3d_radnerf_sr.yaml --exp_name=motion2video_nerf/may_head --reset

# è®­ç»ƒ Torso NeRF æ¨¡å‹
CUDA_VISIBLE_DEVICES=0 python tasks/run.py --config=egs/datasets/May/lm3d_radnerf_torso_sr.yaml --exp_name=motion2video_nerf/may_torso --hparams=head_model_dir=checkpoints/motion2video_nerf/may_head --reset

```

**æ¨ç†**

```
# ä½¿ç”¨æˆ‘ä»¬æä¾›çš„æ¨ç†è„šæœ¬.
CUDA_VISIBLE_DEVICES=0  python inference/genefacepp_infer.py --head_ckpt= --torso_ckpt=/home/lgd/common/GeneFacePlusPlus/checkpoints/motion2video_nerf/may_torso/ --drv_aud=/home/lgd/common/GeneFacePlusPlus/audio_0609.wav

# --debug é€‰é¡¹å¯ä»¥å¯è§†åŒ–ä¸€äº›ä¸­é—´è¿‡ç¨‹ä¸ç‰¹å¾
CUDA_VISIBLE_DEVICES=0  python inference/genefacepp_infer.py --head_ckpt= -torso_ckpt=/home/lgd/common/GeneFacePlusPlus/checkpoints/motion2video_nerf/may_torso/ --drv_aud=/home/lgd/common/GeneFacePlusPlus/audio_0609.wav --debug
```    